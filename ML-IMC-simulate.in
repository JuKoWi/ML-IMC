# Global parameters

systemFiles           = 100CH3OH-CG.in              # Comma-separated list of input filepaths, each defining a system for training or simulation.
symmetryFunctionFile  = symmetry-functions.in       # File containing definitions of symmetry functions used for atomic descriptors.
mode                  = simulation                  # Mode of operation: "training" for optimizing the neural network, "simulation" for running MC simulations with a trained model.
outputMode            = verbose                     # Level of output detail: "default" for essential output, "verbose" for additional trajectory files.
modelFile             = [SET_YOUR_MODEL_FILE]       # File to load a pre-trained neural network model. Use "none" to start from random weights.
gradientsFile         = none                        # File to load pre-calculated gradients. Use "none" for default initialization.
optimizerFile         = none                        # File to load the optimizer state. Use "none" for default initialization.
adaptiveScaling       = false                       # Whether to scale gradients based on individual system losses (true) or use uniform averaging (false).


# Monte Carlo parameters

steps          = 2500000                # Total number of Monte Carlo simulation steps.
Eqsteps        = 500000                 # Number of equilibration steps before data collection begins.
stepAdjustFreq = 5000                   # Frequency (in steps) for adjusting the maximum MC displacement to achieve the target acceptance ratio.
trajout        = 5000                   # Frequency (in steps) for writing the system configuration to a trajectory file.
outfreq        = 1000                   # Frequency (in steps) for writing energy and other data to output files.


# Network parameters

neurons         = 40, 30, 20, 1                     # Number of neurons in each hidden layer of the neural network, followed by the number of output neurons. 
iters           = 10                                # Number of training iterations for the neural network.
bias            = true                              # Whether to use bias parameters in the neural network layers.
activations     = identity, relu, relu, identity    # Activation functions for each layer of the neural network (must match the number of layers).
REGP            = 0.0                               # L2 regularization parameter for the neural network weights (0.0 disables regularization).
optimizer       = AMSGrad                           # Optimization algorithm for training the neural network (recommended: AMSGrad, Adam, AdamW). See https://fluxml.ai/Flux.jl/stable/training/optimisers/ for more options.
rate            = 0.0001                            # Learning rate for the optimizer.
momentum        = 0.9                               # Momentum coefficient used in momentum-based optimizers like AMSGrad and Adam.
decay1          = 0.9                               # First decay parameter used in Adam-based optimizers.
decay2          = 0.999                             # Second decay parameter used in Adam-based optimizers.


# Pre-training parameters

PTsteps         = 10000         # Number of Monte Carlo steps for pre-training the neural network.
PToutfreq       = 100           # Frequency (in steps) for reporting progress during pre-training.
PTREGP          = 0.0           # L2 regularization parameter for pre-training (0.0 disables regularization).
PToptimizer     = AMSGrad       # Optimizer for pre-training (same options as `optimizer`).
PTrate          = 0.0005        # Learning rate for the pre-training optimizer.
PTmomentum      = 0.9           # Momentum coefficient for the pre-training optimizer.
PTdecay1        = 0.9           # First decay parameter for the pre-training optimizer.
PTdecay2        = 0.999         # Second decay parameter for the pre-training optimizer.